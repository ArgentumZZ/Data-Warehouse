## Data Warehouse

- **Data Warehouse**
  - Extract, transform and load data from different sources into a PostgresSQL database.
- **Main folders**
  - `dags` - DAG files for Airflow.
  - `connectors` - Connectors to different DB and non-DB sources.
  - `utilities` - Utilities files.
  - `metadata/logs` - Logs generated for each project's run.
  - `metadata/output` - Files generated for each project's run.
  - `tests` - Unit tests.
  - `warehouse` - Dim and fact tables.
  - `views` - Custom views.
  - `data_quality_checks` - Custom data quality checks.
  - `aggregations` - Data aggregations.
  - `docker` - Dockerfile, requirements.txt and .sh run files.
  - `custom_code` - Custom code for each project.
  - `sript_factory` - Central assembly factory, take info from all other files to create the tasks for execution.
  - `script_runner` - Files (`.bat / .sh`) that run `script_runner.py` which initializes the `script_factory.py`.
- **Main files**
  - `etl_audit_manager.py` - audit table.
  - `etl_utils.py` - general ETL utils functions.
  - `script_worker.py` - custom functions for a given project. 
  - `sql_queries.py` - SQL queries that are parametrized.
  - `alter_tables.sql` - Track executed SQL queries. 
  - `script_factory.py` - Assemble the tasks for the project.
  - `script_runner.py` - Run the tasks in `script_factory.py`.
  - `.bat/.sh` files to run `script_runner.py`.
-------------------------------
## General structure
```
datawarehouse/
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ venv/
‚îÇ
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îú‚îÄ‚îÄ local/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ db_config.cfg
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ keyfile_1.pem
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ keyfile_2.pkk
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ setenv.bat
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ setenv.sh
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ... other pem/pkk files ...
‚îÇ
‚îú‚îÄ‚îÄ dags/
‚îÇ   ‚îú‚îÄ‚îÄ dwh_main_dag.py
‚îÇ   ‚îî‚îÄ‚îÄ ... other DAG .py files ...
‚îÇ
‚îú‚îÄ‚îÄ etls/
‚îÇ   ‚îú‚îÄ‚îÄ _templates/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ (general template files)
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ aggregations/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ aggregation_1_revenue/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ... other aggregation projects ...
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ connectors/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ postgresql_connector.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ mysql_connector.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ oracle_connector.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ... other connectors...
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ data_quality_checks/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dqc_1_calculate_record_discrepancies/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ... other DQC projects ...
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ datastore/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ alpaca_1_revenue/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ crypto_1_transactions/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ financial_data_1_ethereum/
‚îÇ   ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ custom_code/
‚îÇ   ‚îÇ   ‚îÇ       ‚îÇ      ‚îú‚îÄ‚îÄ alter_tables.sql
‚îÇ   ‚îÇ   ‚îÇ       ‚îÇ      ‚îú‚îÄ‚îÄ script_factory.py
‚îÇ   ‚îÇ   ‚îÇ       ‚îÇ      ‚îú‚îÄ‚îÄ script_parameters.py
‚îÇ   ‚îÇ   ‚îÇ       ‚îÇ      ‚îú‚îÄ‚îÄ script_worker.py
‚îÇ   ‚îÇ   ‚îÇ       ‚îÇ      ‚îî‚îÄ‚îÄ sql_queries.py
‚îÇ   ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ docker/
‚îÇ   ‚îÇ   ‚îÇ       ‚îÇ      ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îÇ   ‚îÇ       ‚îÇ      ‚îú‚îÄ‚îÄ requirements.py
‚îÇ   ‚îÇ   ‚îÇ       ‚îÇ      ‚îú‚îÄ‚îÄ run_financial_data_1_ethereum_docker.bat
‚îÇ   ‚îÇ   ‚îÇ       ‚îÇ      ‚îî‚îÄ‚îÄ run_financial_data_1_ethereum_docker.sh
‚îÇ   ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ metadata/
‚îÇ   ‚îÇ   ‚îÇ       ‚îÇ      ‚îú‚îÄ‚îÄ logs/
‚îÇ   ‚îÇ   ‚îÇ       ‚îÇ      ‚îÇ      ‚îú‚îÄ‚îÄ 2026-01-18_11-36-19_etl.log
‚îÇ   ‚îÇ   ‚îÇ       ‚îÇ      ‚îÇ      ‚îú‚îÄ‚îÄ 2026-01-18_11-40-17_etl.log
‚îÇ   ‚îÇ   ‚îÇ       ‚îÇ      ‚îÇ      ‚îî‚îÄ‚îÄ ... other log _etl.log files ...
‚îÇ   ‚îÇ   ‚îÇ       ‚îÇ      ‚îú‚îÄ‚îÄ output/
‚îÇ   ‚îÇ   ‚îÇ       ‚îÇ      ‚îÇ      ‚îú‚îÄ‚îÄ 2026-01-18_11-36-19.csv
‚îÇ   ‚îÇ   ‚îÇ       ‚îÇ      ‚îÇ      ‚îú‚îÄ‚îÄ 2026-01-18_11-40-17.csv
‚îÇ   ‚îÇ   ‚îÇ       ‚îÇ      ‚îÇ      ‚îî‚îÄ‚îÄ ... other output .csv files ...
‚îÇ   ‚îÇ   ‚îÇ       ‚îÇ      ‚îú‚îÄ‚îÄ dictionary.yaml
‚îÇ   ‚îÇ   ‚îÇ       ‚îÇ      ‚îú‚îÄ‚îÄ mapping.yaml
‚îÇ   ‚îÇ   ‚îÇ       ‚îÇ      ‚îú‚îÄ‚îÄ schema.yaml
‚îÇ   ‚îÇ   ‚îÇ       ‚îÇ      ‚îú‚îÄ‚îÄ validation.yaml
‚îÇ   ‚îÇ   ‚îÇ       ‚îÇ      ‚îî‚îÄ‚îÄ ... other .yaml files ...
‚îÇ   ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ script_runner/
‚îÇ   ‚îÇ   ‚îÇ       ‚îÇ      ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îÇ       ‚îÇ      ‚îú‚îÄ‚îÄ run_financial_data_1_ethereum.bat
‚îÇ   ‚îÇ   ‚îÇ       ‚îÇ      ‚îú‚îÄ‚îÄ run_financial_data_1_ethereum.sh
‚îÇ   ‚îÇ   ‚îÇ       ‚îÇ      ‚îî‚îÄ‚îÄ run_script.py
‚îÇ   ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ test/
‚îÇ   ‚îÇ   ‚îÇ       ‚îÇ      ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îÇ       ‚îÇ      ‚îú‚îÄ‚îÄ test_connectors.py
‚îÇ   ‚îÇ   ‚îÇ       ‚îÇ      ‚îú‚îÄ‚îÄ test_utilspy
‚îÇ   ‚îÇ   ‚îÇ       ‚îÇ      ‚îú‚îÄ‚îÄ test_worker.py
‚îÇ   ‚îÇ   ‚îÇ       ‚îÇ      ‚îî‚îÄ‚îÄ ... other test .py files ...
‚îÇ   ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ... other datastore project folders ...
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ utilities/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ argument_parser.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ email_manager.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ etl_audit_manager.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ etl_utils.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ date_utils.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ db_utils.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dq_utils.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ file_utils.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ... other utils files ...
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ warehouse/
‚îÇ       ‚îú‚îÄ‚îÄ dim_1_dim_crypto_transactions/
‚îÇ       ‚îú‚îÄ‚îÄ dim_1_staging_crypto_transactions/
‚îÇ       ‚îú‚îÄ‚îÄ fact_1_fact_shares_revenue/
‚îÇ       ‚îú‚îÄ‚îÄ fact_1_staging_shares_revenue/
‚îÇ       ‚îú‚îÄ‚îÄ ... other warehouse project folders ...
‚îÇ       ‚îÇ  
‚îÇ       ‚îî‚îÄ‚îÄ views/
‚îÇ             ‚îú‚îÄ‚îÄ view_1_revenue.py
‚îÇ             ‚îî‚îÄ‚îÄ ... other view files ...
```
___
## üìù Project To‚ÄëDo Plan

- **Partial Task Functions**
  - Add parameter‚Äëaccepting partial functions inside `script_factory.py`. ‚úîÔ∏è
  - Improve modularity and reusability of task definitions. ‚úîÔ∏è
  - Add task name and description, retries, is_enabled and dependency parameters. ‚úîÔ∏è

- **ETL Audit Manager**
  - Create an audit table to track project's run metadata. ‚úîÔ∏è
  - Capture `start/end_load_date`, `start/end_script_execution_time`,` data_min/max_dates`, `status`, `number_of_records`, `environment`, `script_version`, `load_type`, `previous_max_date`, `target_database`, `target_table`. ‚úîÔ∏è 
  - Create a `create_etl_runs_table` function. ‚úîÔ∏è
  - Create an `insert_etl_runs_record` function. ‚úîÔ∏è
  - Create an `update_etl_runs_record` function. ‚úîÔ∏è
  
- **ETL Utilities**
  - Add custom ETL transformation functions. ‚úîÔ∏è
  - Add a single `transform_dataframe` function that applies transformations. ‚úîÔ∏è
  - Add `process_dataframe_date_ranges` function to calculate `data_min_date` and `data_max_date`. ‚úîÔ∏è

- **Incremental and full Load**
  - Implement logic for both incremental (I) and full (F) load modes. ‚úîÔ∏è
  - Override internal defaults with values from `.bat file.` ‚úîÔ∏è

- **Logging**
  - Create a logging_manager.py to standardize log format. ‚úîÔ∏è
  - Create a `logs/` folder to store logs for each project's run. ‚úîÔ∏è
  - (Optionally) Automatically delete .logs older than 7 days. ‚úîÔ∏è
  - (Optionally) Automatically delete .logs older than N runs. ‚úîÔ∏è
  
- **Utilities folder**
  - Create utilities .py files for ETL processes (e.g. file_utils.py, argument_parser.py, errors_utils, db_utils.py)Ô∏è. ‚úîÔ∏è

- **Output folder**
  - Create an `output/` folder to store generated files. ‚úîÔ∏è
  - Format `output/file_name_timestamp.csv`. ‚úîÔ∏è
  - Control with a boolean operator, whether the file will be deleted from the folder. ‚úîÔ∏è

- **Containerization**
  - Add a `Dockerfile` for containerized execution. ‚úîÔ∏è
  - Update `_docker.bat` to run the container. ‚úîÔ∏è
  - Update `_docker.sh` to run the container.
  - Ensure compatibility with Windows/Linux.

- **Launcher scripts**
  - Update `.bat` ‚úîÔ∏è, `_docker.bat` ‚úîÔ∏è, `.sh`, `_docker.sh`.
  - Add parameter parsing and variable definitions. ‚úîÔ∏è
  - Add logs and error handling. ‚úîÔ∏è

- **Email Notifications (SMTP)**
  - Implement e-mail success/failure alerts after each project's run.
  - Include run summary and error details.
  - Add business, admin and error recipients.
  - Add boolean operators to control whether the recipients should receive an e-mail.

- **Backfill**
  - Implement backfill loading option in `.bat` ‚úîÔ∏è, `_docker.bat` ‚úîÔ∏è, `.sh`, `_docker.sh` files.
  - Create a separate backfill project that accepts `project_name`, `start_date`, `end_date`, `load_days` to run a given project and load data incrementally.

- **Fact and dimensional tables**
  - Add staging and normal fact and dimensional tables (staging_dim -> warehouse_dim -> staging_fact -> warheouse_fact). 
  - Build a staging_dim table to extract data from the source and checks for null values, duplicates, missing data.
  - In warehouse_dim, implement slowly changing dimensions (type 1 and type2) updates - close SCD2 rows, insert new SCD2 rows, apply SCD1 updates and insert new rows.
  - Add indices for SCD detection and ETL MERGE/UPDATEs, partial unique index, fast fact and point-in-time lookups, prevent SCD2 ranges overlapping.
  - Implement staging_fact table to extract data from the source, correct fact grain and data quality checks.
  - In warehouse_fact, enforce referential integrity to prevent orphaned surrogate keys, partition the table by date/date_key, add partition-based deletion and build an index strategy.

- **Orchestration**
  - Implement orchestration with Airflow.
  - Build DAG for specific cases (daily, 30 min , weekly, monthly DAGs).

- **Monitoring**
  - Implement data warehouse health monitoring with dashboards in Apache Superset (or similar tools).
  - Build reports to monitor blocked queries, long-running queries, index efficiency and usage, dead tuple counts (vacuum and bloat monitoring).
  - Buffer cache and I/O performance, connection pool health, add transaction and throughput metrics.

- **Data quality checks**
  - Add general data quality checks that run after the DAGS.
  - Monitor record discrepancies, null values, referential integrity, SLA checks (arrival delay), schema drift.

- **Documentation**
  - Add documentation explaining the different modules and processes in the data warehouse (in Confluence).

- **Connectors**
  - Add more connectors:
  - PostgreSQL (implemented) ‚úîÔ∏è  
  - Oracle
  - MySQL
  - Salesforce
  - MSSQL
  - Snowflake
  - Google BigQuery
  - S3